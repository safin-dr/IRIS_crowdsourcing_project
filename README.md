# IRIS

В этом репозитории находится код для препроцессинга данных для разметки и подготовки самой разметки, а также код для обучения модели бинарной классификации и генерации финальных предсказаний.

## Описание работы над проектом

### Пайплайн

Работу над проектом мы построили следующим образом:

- для экономии ресурсов в начале обучили пару ResNet-like моделей на имеющихся ground-truth данных;
- научились извлекать эмбеддинги для картинок, заменив последний слой модели;
- по расположению объектов с разным таргетом в пространстве эмбеддингов поняли, что у объектов одного класса получаются близкие эмбеддинги (при этом пересечение классов, конечно, непустое);
- извлекли эмбеддинги для всех имеющихся картинок, оценили количество неразмеченных картинок, которые можно достоверно классифицировать с помощью kNN или кластеризации в пространстве эмбеддингов; 
- выделили "проблемные" картинки - то есть те, которые в пространстве эмбеддингов ни с помощью KNN, ни с помощью кластеризации не получается достоверно определить к одному из классов;
- отправили на разметку "проблемные" и картинки, у которых в пространстве эмбеддингов среди ближайших соседей есть "проблемные" картинки;
- собрали итоговый датасет из ground-truth, размеченных толокерами и ранее достоверно классифицированных картинок;
- обучили на итоговом датасете KNN, перебрали у него немного гиперпараметров и применили к потенциально оставшимся неразмеченным картинкам (так как они немного могли меняться при разных инициализациях шага 2);
- после полученного полного датасета обучили ResNet-like модели.

В качестве моделей мы взяли три предобученные на Imagenet ResNet из библиотеки `torchvision` - resnet-18, resnet-80, resnet-152[^1].

#### Более подробно про идею с KNN псевдолейблингом

Перед тем как перейти к этой затее, мы проверили полученные эмбеддинги на адекватность - трансформировали их через tSNE и посмотрели на близкие точки в разных местах полученного облака - выяснилось, что изображения с похожими структурами действительно находятся рядом в пространстве эмбеддингов. И к тому же наиболее "очевидные" изображения, явно относящиеся к одному из классов, находились рядом со своими соседями из того же класса, это было хоорошим признаком, позволившим нам вложится в подход связанный с KNN.

Мы не ограничилисиь одним KNN-классификатором, мы взяли их ансамбль, состоящий из моделей с разными гиперпараметрами. Каждый из представителей ансамбля был обучен на эмбеддингах размеченных данных. Затем весь неразмеченный датасет был скормлен ансамблю из KNN. Далее если большинство членов ансамбля уверенно предсказывают принадлежность соответствующего эмбеддинга к одному из классов - картинке присваивался предварительный соответствующий лейбл. Если классификаторы были несогласованы в своем решении - картинка помечалась как "проблемная".

Затем для дальнейшего поиска "проблемных" картинок и увеличения достоверности не-"проблемных" картинок мы дополнили алгоритм разметки кластеризацией KMEANS++ - число кластеров взяли равным количеству размеченных картинок - 200 - и начальные центроиды для каждого из кластеров - это соответствующие эмбеддинги каждой из размеченной картинки. Далее мы кластеризовали все эмбеддинги на эти 200 кластеров, и каждойкартинке вновь присвоили лейбл, соответствующий лейблу начальной центроиды для данного кластера.

Таким образом, у нас получилось два полуавтоматических лейбла - полученного от ансамбля kNN и от кластеризации. Далее, если у картинки в обоих случаях лейбл одинаковый и она не является "проблемной" - этй картинке присваивается однозначный полуавтоматический лейбл. Если же есть расхождение в показаниях двух лейблов либо если картинка проблемная - то ей присваивается лейбл "проблемная". Таким образом получилось отобрать примерно 1/6 всех картинок как "проблемные" - это целевое множество, которое предстояло разметить толокерам. Далее это множество мы дополнили картинками, которые в пространстве эмбеддингов имели "проблемных" соседей. Итого получилось, что на разметку отправили около 9.3К картинок вместо 33К.

Затем после получения разметки мы ее саггрегировали и с помощью kNN распространили на оставшиеся неразмеченные картинки.

Данный подход позволил сэкономить ресурсы на разметку и в то же время получить качество 81 на тестовом датасете в контесте.

### Разметка

Пайплайн разметки выглядел следующим образом:

- создали html файл с описанием, через API настроили проект;
- разделили ground-truth датасет на 3 части: 30 объектов на обучение, 20 на экзамен, оставшиеся на ханипоты;
- добавили информативные подсказки на обучении;
- для экзамена установили большое перекрытие, чтобы достаточное число исполнителей смогло добраться до боевой разметки;
- назначали навык исполнителям, достаточно успешно справившимся с экзаменационной разметкой;
- в пул с боевой разметкой добавили "проблемные" картинки и ханипоты, установили перекрытие 3;
- настроили контроль качества: быстрые ответы, точность на ханипотах, мнение большинства;
- выставили 1 ханипот на страницу из 50 заданий, поэтому исполнителям не представлялось возможным "слить" базу данных ханипотов для недобросовестной разметки;
- запустили все пулы, собрали данные.

### Структура репозитория

Папка `Crowdsourcing` содержит все необходимое для создания проекта разметки (ноутбук запускался из гугл колаба, часть настроек основного пула в конце выставлялись через UI). Файлы с ханипотами, экзаменом и обучением получены из `hw_3_markup_data.txt`.

Папка `Training` содержит все необходимое для подготовки данных для разметки и конечное обучение на размеченном датасете:

- `setup_data.sh` - содержит пример настройки и скачивания всех картинок. Для тестового датасета необходимы была дополнительная обработка - конвертация в csv их xlsx и удаление служебных символов с конца строки - после которых можно было применять аналогичные команды для скачивания;
- `EDA.ipynb` содержит первичный анализ данных[^2], подготовку данных для разметки (выделение подмножества "проблемных") картинок и сохранение эмбеддингов;
- `full_scale_training.ipynb` интегрирует полученный датасет, собирает и применяет финальную аггрегацию к неразмеченным семлпам, сплитит датасет, обучает модели и собирает посылку для контеста.

**Важно** - для соблюдения актуальности данных мы не публикуем в репозитории реальные файлы заданий и тестовый датасет, поэтому команды из `setup_data.sh` не будут выполнены.

[^1]: Самым оптимальным вариантом оказался resnet-18, так как показал сравнимое качество при скорости обучения, в 10 раз выше чем у resnet-152. Во время полноценного обучения попробовали заменять последний слой как на простой линейный слой, так и на MLP. Также убедились, что для лучшего качества необходим LRScheduler, выбрали использовать трансформерный, так как в нем есть warmup и постепенное снижение learning rate-а к концу обучения, также кривая learning rate-a зависит от внутренней размерности модели - мы эмпирически взяли это число как количество внутренних каналов resnet-152, равное 256.
[^2]: Так, например, после первичного анализа мы узнали, что подавляющее большинство картинок имеет размер 128*128, что сузило спектр подходящих моделей (к примеру ViTы из torchvision ожидают на вход картинки побольше).
